{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "3c439c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "## 标签映射错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3eee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 保存 vit-b/32 k400的表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "c4bd6a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../lists/k400_cls_feas512_vitb_32','rb') as f:\n",
    "    k400=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "6a3f6bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../lists/hmdb51_cls_feas512_vitb_32','rb') as f:\n",
    "    hmdb51=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "id": "d4f29bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../test_records/ucf101/ViT-B/32/clip_before_one_temporal/video_features','rb') as f:\n",
    "    video_hmdb51=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "5f6eebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../test_records/ucf101/ViT-B/32/clip_before_one_temporal/pre_labels','rb') as f:\n",
    "    labels_hmdb51=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "5abb0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../test_records/k400/ViT-B/32/k400_visual_center/visual_center','rb') as f:\n",
    "    k400_visual_center=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "2c2b392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmdb51_norm=hmdb51/hmdb51.norm(dim=-1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "d2b385c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.5413, 0.5406, 0.1030, 0.0838, 0.0748, 0.0739, 0.0635, 0.0619, 0.0609,\n",
       "        0.0606]),\n",
       "indices=tensor([133, 312, 493, 441, 143, 479,  43,  73,  67, 311]))"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmdb51_norm[31].topk(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "cc3fba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds=(-4.5*video_hmdb51[0]).topk(10).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "c8af8370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3921, -0.7358, -0.3985, -0.3935, -0.3875, -0.3786, -0.3602, -0.3405,\n",
       "        -0.3383, -0.3238])"
      ]
     },
     "execution_count": 817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(-4.5*video_hmdb51[0]).topk(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "eee40d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1044, -0.0504, -0.0086, -0.0029, -0.0505,  0.0117, -0.0244,  0.0245,\n",
       "        -0.1046, -0.0611])"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmdb51_norm[31][inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "cb375e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.0353, 0.0233, 0.0228]),\n",
       "indices=tensor([31, 32, 48]))"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4.5*video_hmdb51[0]@hmdb51_norm.T).softmax(dim=-1).topk(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video=video_hmdb51[1][video_hmdb51[1]<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "id": "6ffcdb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31, 30, 48, 28, 38, 31])"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_hmdb51[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "61a47c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_fea=video_hmdb51.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "id": "0cd03030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6766, 1, 512])"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_fea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "38ca210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmdb51_norm1=hmdb51_norm.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "1e481a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumsame=torch.sum(((hmdb51_norm1>0) & (video_fea>0)) | ((hmdb51_norm1<0) & (video_fea<0)),dim=-1).topk(1).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "76a1844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=(4.6*video_hmdb51@hmdb51_norm.T).softmax(dim=-1).topk(1).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "b20c8188",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmdb_true_label=labels_hmdb51[:,-1]\n",
    "# ucf101_true_label=labels_ucf101[:,-1]\n",
    "hmdb_true_label=hmdb_true_label.unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "id": "8e02e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trueratio=sum((sumsame==hmdb_true_label)&(indices==hmdb_true_label)).numpy()[0]/video_hmdb51.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "id": "998bd767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3151049364469406"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32549155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8133ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "43280741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31, 32, 48, 49, 13, 31])"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_hmdb51[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "4f57ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettest_train(test_datas,train_datas):\n",
    "    '''\n",
    "    为测试集生成任务相关的训练文本指引\n",
    "    '''\n",
    "    test_datas/=test_datas.norm(dim=1,keepdim=True)\n",
    "    train_datas/=train_datas.norm(dim=1,keepdim=True)\n",
    "    similarity=(100*test_datas@train_datas.T).softmax(dim=-1)\n",
    "    values=similarity.softmax(dim=-1).topk(3).values.softmax(dim=-1)\n",
    "    indices=similarity.softmax(dim=-1).topk(3).indices\n",
    "#     return indices\n",
    "    return train_datas[indices].mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "id": "994863c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coltrain_hmdb51=gettest_train(ucf101_in_gr,k400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "id": "cd5e1339",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmdb_true_label=labels_hmdb51[:,-1]\n",
    "# ucf101_true_label=labels_ucf101[:,-1]\n",
    "hmdb_true_label=hmdb_true_label.unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "id": "b83cb78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(video_feas,cls_feas,coltrain,true_las,ratio):\n",
    "#     coltrain=k400_visual_center[coltrain].mean(dim=1)\n",
    "    simi_visual=(100*video_feas@coltrain.T).softmax(dim=-1)\n",
    "    similarity=(100*video_feas@cls_feas.T).softmax(dim=-1)\n",
    "    all_simi=ratio*simi_visual+(1-ratio)*similarity\n",
    "    indices=all_simi.softmax(dim=-1).topk(1).indices\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "id": "e8fa5fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "res_hmdb51=[]\n",
    "# res_ucf101=[]\n",
    "for i in range(0,11):\n",
    "    ratio=i/10\n",
    "    x.append(ratio)\n",
    "#     print(ratio)\n",
    "    indices=get_accuracy(video_hmdb51,ucf101_in_gr,coltrain_hmdb51,hmdb_true_label,ratio)\n",
    "    trueratio=sum(indices==hmdb_true_label).numpy()[0]/video_hmdb51.shape[0]\n",
    "    res_hmdb51.append(trueratio)\n",
    "    \n",
    "#     indices=get_accuracy(video_ucf101,ucf101,coltrain_ucf101,ucf101_true_label,ratio)\n",
    "#     trueratio=sum(indices==ucf101_true_label).numpy()[0]/video_ucf101.shape[0]\n",
    "#     res_ucf101.append(trueratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "id": "14a4d76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7774932208496536,\n",
       " 0.7781711358843025,\n",
       " 0.777342573064176,\n",
       " 0.772597167821633,\n",
       " 0.7676257909008738,\n",
       " 0.7594908104850858,\n",
       " 0.7417143717987346,\n",
       " 0.7195691473335342,\n",
       " 0.6794215125037661,\n",
       " 0.6301596866526062,\n",
       " 0.5530280204880988]"
      ]
     },
     "execution_count": 912,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_hmdb51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "b94e8d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7110575474540525,\n",
       " 0.7110575474540525,\n",
       " 0.7114341669177463,\n",
       " 0.7122627297378729,\n",
       " 0.7121120819523953,\n",
       " 0.713919855378126,\n",
       " 0.513859596263935,\n",
       " 0.4212865320879783,\n",
       " 0.3706688761675203,\n",
       " 0.34829768002410366,\n",
       " 0.33052124133775235]"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ucf101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "32ec797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d4a6157b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.randn((4,8,512))\n",
    "a[:,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e3495ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_ids = torch.arange(8, dtype=torch.long)\n",
    "position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4435b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_position_embeddings = torch.nn.Embedding(77, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ad6fbd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_position_embeddings(position_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "166bcaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(77, 512)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "9732647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "num=sorted(os.listdir('../../UCF_101_frame_org/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "473ecc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "c04c619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k400acs=[i.strip().split(',')[1] for i in open('../lists/ucf101_action_gra.txt').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "e6e65ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(101):\n",
    "    ac=k400acs[i]\n",
    "    ac=ac.replace(' ','_')\n",
    "    nu=num[i].replace(' ','_')\n",
    "    if nu!=ac:\n",
    "        print(nu,ac,i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8127bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=512 ** -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cf8af3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_embedding=torch.nn.Parameter(scale*torch.randn(512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "dc3d1480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c3769287",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn((2,8,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a5c89cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "de3a0bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.zeros(2, 1,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a7039807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0104, -0.0285, -0.0653,  ..., -0.0244, -0.0131,  0.0068]],\n",
       "\n",
       "        [[-0.0104, -0.0285, -0.0653,  ..., -0.0244, -0.0131,  0.0068]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_embedding+torch.zeros(2, 1,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6d1a0273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 512])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.randn((2,512))\n",
    "a=torch.unsqueeze(a,dim=1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "31c8132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn((2,8,512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd585a6a",
   "metadata": {},
   "source": [
    "## 构造不同的prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "601a473f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout used:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "dropout used:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "loading clip pretrained model!\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\") \n",
    "import clip\n",
    "import torch\n",
    "import pickle\n",
    "clip_model, clip_state_dict = clip.load('ViT-B/32',\n",
    "                             device='cpu',jit=False,\n",
    "                             internal_modeling=False,\n",
    "                             T=8,\n",
    "                             dropout=0.0,\n",
    "                            emb_dropout=0.0,\n",
    "                            pretrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c052272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a60050",
   "metadata": {},
   "outputs": [],
   "source": [
    "'../25_af.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2a36478",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=Image.open('../25_af.png').convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf4c656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8032b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Textencoder(nn.Module):\n",
    "    def __init__(self,clip_model) :\n",
    "        super().__init__()\n",
    "        # self.vocab_size=clip_model.vocab_size\n",
    "        self.transformer=clip_model.transformer\n",
    "        self.positional_embedding=clip_model.positional_embedding\n",
    "        self.emb_dropout = clip_model.emb_dropout\n",
    "        self.text_projection =clip_model.text_projection\n",
    "        self.ln_final=clip_model.ln_final\n",
    "    def encode_text(self, prompts,tokenized_prompts):\n",
    "        '''\n",
    "        prompts: 为prompt+class_name token_embedding的结果\n",
    "        tokenized_prompts：为prompt+class_name 分词的结果\n",
    "        '''\n",
    "        # x = self.token_embedding(text).type(self.dtype)  # [batch_size, n_ctx, d_model]\n",
    "\n",
    "        x = prompts + self.positional_embedding.type(self.dtype)\n",
    "        if self.emb_dropout > 0:\n",
    "            x = self.dropout(x)\n",
    "        x = x.permute(1, 0, 2)  # NLD -> LND\n",
    "        x = self.transformer(x)\n",
    "        x = x.permute(1, 0, 2)  # LND -> NLD\n",
    "        x = self.ln_final(x).type(self.dtype)\n",
    "\n",
    "        # x.shape = [batch_size, n_ctx, transformer.width]\n",
    "        # take features from the eot embedding (eot_token is the highest number in each sequence)\n",
    "        x = x[torch.arange(x.shape[0]), tokenized_prompts.argmax(dim=-1)] @ self.text_projection\n",
    "\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df524245",
   "metadata": {},
   "outputs": [],
   "source": [
    "textual=Textencoder(clip_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19bd3301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for name,param in textual.named_parameters():\n",
    "#     print(name)\n",
    "# clip_model.ln_final.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29e706b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(49408, 512)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_model.token_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0187ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prompt_test(data):\n",
    "    text_aug = ['a video of a person {}.']\n",
    "    text_dict={}\n",
    "    num_text_aug=len(text_aug)\n",
    "    for ii,txt in enumerate(text_aug):\n",
    "        text_dict[ii]=torch.cat([clip.tokenize(txt.format(c)) for c in data])\n",
    "    feature=text_dict[0]\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae786682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "## 获取在知识图谱中的类别\n",
    "k400_acs=[i.strip().split(',')[1] for i in open('../lists/ucf101_action_gra.txt').readlines()]\n",
    "k400_acs=np.array(k400_acs)\n",
    "token1=text_prompt_test(k400_acs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85aa4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ucf101_in_gr=clip_model.encode_text(token1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63952740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86326747",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucf101_in_gr/=ucf101_in_gr.norm(dim=-1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7319ade6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0022,  0.0148,  0.0101,  0.0300, -0.0107])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ucf101_in_gr[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "id": "4918c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('../lists/ucf101_cls_feas512_vitl_14_org','wb')\n",
    "pickle.dump(ucf101_in_gr,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "b177201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettest_train_str(test_datas,train_datas):\n",
    "    '''\n",
    "    为训练集的类别选择最为相似的5个类别\n",
    "    '''\n",
    "    test_datas/=test_datas.norm(dim=1,keepdim=True)\n",
    "    train_datas/=train_datas.norm(dim=1,keepdim=True)\n",
    "    similarity=(100*test_datas@train_datas.T).softmax(dim=-1)\n",
    "#     values=similarity.softmax(dim=-1).topk(3).values.softmax(dim=-1)\n",
    "    indices=similarity.softmax(dim=-1).topk(3).indices.numpy()\n",
    "#     return indices\n",
    "#     strr=','.join\n",
    "    colacs=k400_acs[indices]\n",
    "    re=[]\n",
    "    for ac in colacs:\n",
    "        re.append(','.join(ac))\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "3297f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "colacsstr=gettest_train_str(hmdb51,k400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "880766e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "colacsstr_token=text_prompt_test(colacsstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "9c72853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    cls1=clip_model.encode_text(colacsstr_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a00c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "bcc44f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clapping,applauding,pumping fist'"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= ['clapping', 'applauding', 'pumping fist']\n",
    "','.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5269c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### hmdb51 选择前5个prompt会有一定的提升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "8d749043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "216efe96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0281,  0.0211, -0.0110,  ..., -0.0354, -0.0097, -0.0311],\n",
       "        [ 0.0748,  0.0356, -0.0177,  ..., -0.0302,  0.0383,  0.0285],\n",
       "        [ 0.0467,  0.0272,  0.0116,  ...,  0.0299,  0.0157, -0.0400],\n",
       "        ...,\n",
       "        [ 0.0223, -0.0224, -0.0048,  ..., -0.0474,  0.0395,  0.0114],\n",
       "        [ 0.0336,  0.0019, -0.0107,  ..., -0.0359, -0.0388, -0.0034],\n",
       "        [ 0.0273,  0.0202, -0.0116,  ..., -0.0273, -0.0012,  0.0204]])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "51ed20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[i.strip().split(',')[0] for i in open('../lists/ucf101_action_gra.txt').readlines()]\n",
    "or_labels=[i.strip().split(',')[1] for i in open('../lists/ucf101_labels.txt').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "395b78aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_la=[i for i in  sorted(os.listdir('../../UCF_101_frame_org/'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "68331542",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(labels)):\n",
    "    if frames_la[i]!=or_labels[i]:\n",
    "        print(frames_la[i],or_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "1922b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('../lists/ucf101_action_gra.txt','a')\n",
    "for la in labels:\n",
    "    la=la.replace(' ',',')\n",
    "    f.write(la+'\\n')\n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "5763fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels=[i.strip() for i in open('../lists/k600_labels.txt').readlines()]\n",
    "f=open('../lists/k600_labels_test.txt','a')\n",
    "for ind,la in enumerate(labels):\n",
    "    f.write(str(ind)+','+la+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "4fb7f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.randn((2,8,512))\n",
    "b=torch.randn((2,8,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "f35cba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.max(a,dim=1).values\n",
    "b=torch.max(b,dim=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "b4d6a760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6476, 0.9748, 2.4323, 1.9777, 1.6841],\n",
       "        [2.3086, 1.6194, 2.4260, 1.0982, 2.8340]])"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(a,b)[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "04d47b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6476, 0.9748, 1.6356, 1.7956, 1.6841],\n",
       "        [1.8022, 1.6194, 1.0366, 0.6992, 2.8340]])"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4115f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6367312",
   "metadata": {},
   "outputs": [],
   "source": [
    "k400=[i.strip().split(',')[1] for i in open('../lists/kinetics_400_labels.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cc6b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind,name in enumerate(sorted(os.listdir('../../kinetics400_frames/'))):\n",
    "    a=k400[ind].replace(' ','_')\n",
    "    if a!=name: \n",
    "        print(k400[ind],name,ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37215361",
   "metadata": {},
   "outputs": [],
   "source": [
    "## KL散度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28f331e",
   "metadata": {},
   "source": [
    "## 文本端的prompt tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94a4c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "k400_acs=[i.strip().split(',')[1] for i in open('../lists/kinetics_400_labels.txt').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6db0ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ctx=8\n",
    "prompt_prefix=\" \".join([\"X\"]*n_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85598b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts=[prompt_prefix + \" \" + name +\".\" for name in k400_acs] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1fd8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_prompts = torch.cat([clip.tokenize(p) for p in prompts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc261b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[49406,   343,   343,  ...,     0,     0,     0],\n",
       "        [49406,   343,   343,  ...,     0,     0,     0],\n",
       "        [49406,   343,   343,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [49406,   343,   343,  ...,     0,     0,     0],\n",
       "        [49406,   343,   343,  ...,     0,     0,     0],\n",
       "        [49406,   343,   343,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94cf554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embedding = clip_model.token_embedding(tokenized_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de4925d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 77, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3c9f669",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_suffix=embedding[:,1+n_ctx:,:] # 类别和结束符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56463cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_prefix=embedding[:,:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98143717",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_vectors = torch.empty(400, n_ctx, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2543df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_vectors=torch.nn.init.normal_(ctx_vectors, std=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dbb6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts=torch.cat([token_prefix,ctx_vectors,token_suffix],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e0388ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0017,  0.0085,  0.0296,  0.0013,  0.0132])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[0,:5,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abdfe840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0017, -0.0397,  0.0341,  0.0196, -0.0152])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[1,:5,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a5c3963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clip.simple_tokenizer import SimpleTokenizer as _Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc090148",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmdb51=[i.strip().split(',')[1] for i in open('../lists/hmdb51_labels.txt').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd1bdce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tokenizer=_Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd60b54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8594, 2225]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tokenizer.encode('brush hair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02f5f48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brush hair',\n",
       " 'cartwheel',\n",
       " 'catch',\n",
       " 'chew',\n",
       " 'clap',\n",
       " 'climb',\n",
       " 'climb stairs',\n",
       " 'dive',\n",
       " 'draw sword',\n",
       " 'dribble',\n",
       " 'drink',\n",
       " 'eat',\n",
       " 'fall floor',\n",
       " 'fencing',\n",
       " 'flic flac',\n",
       " 'golf',\n",
       " 'handstand',\n",
       " 'hit',\n",
       " 'hug',\n",
       " 'jump',\n",
       " 'kick',\n",
       " 'kick ball',\n",
       " 'kiss',\n",
       " 'laugh',\n",
       " 'pick',\n",
       " 'pour',\n",
       " 'pullup',\n",
       " 'punch',\n",
       " 'push',\n",
       " 'pushup',\n",
       " 'ride bike',\n",
       " 'ride horse',\n",
       " 'run',\n",
       " 'shake hands',\n",
       " 'shoot ball',\n",
       " 'shoot bow',\n",
       " 'shoot gun',\n",
       " 'sit',\n",
       " 'situp',\n",
       " 'smile',\n",
       " 'smoke',\n",
       " 'somersault',\n",
       " 'stand',\n",
       " 'swing baseball',\n",
       " 'sword',\n",
       " 'sword exercise',\n",
       " 'talk',\n",
       " 'throw',\n",
       " 'turn',\n",
       " 'walk',\n",
       " 'wave']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmdb51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "399c2f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \u0000a\n",
      "1 \u0001a\n",
      "2 \u0002a\n",
      "0 \u0000a\n"
     ]
    }
   ],
   "source": [
    "s='abca'\n",
    "for i in s:\n",
    "    index=ord(i)-ord('a')\n",
    "    n=chr(index)+'a'\n",
    "    print(index,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3610f995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1d3b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
